
# Outline for Final Paper

## Introduction

My research idea focuses on to access the ability of LLM to modify the given python code for matching certain requirement. The central research problem we want to addresses is the capability of Large Language Models (LLMs) to understand and modify existing Python code to meet new or altered requirements. In the realm of software development in order to form a substantial part of the development lifecycle code maintenance and iterative updates always are necessary. Given that software inevitably evolves over time the ability to swiftly and accurately adapt existing code is crucial for the sustainability and efficiency of software projects. As we know code maintenance and iterative updating code always can be time-consuming for human developers. If LLMs can do better on this job lots of people can be benefits.

## Problem Definition & Metrics

In order to making our experiment more convincing some metrics are utilized for measuring and comparing. The first metric is accuracy which indicates how much the generated -code match the requirement. The second metric is rate of matching requirement which is to measure how much percent of requirement is matched.

## Experiments Design

For accessing the ability of LLM to modify code for matching requirement we will design several experiments. A given requirement and original code will be fed GPT and let GPT to modify the code to match the requirement. For any single test the given requirement may be included a series of sections for make test more comprehensive. In addition we will make requirement focus on various aspects in order to guarantee the diversity of our experiment.

## Conclusion

According the results of evaluation for experiments we can access the ability of LLM to modify code for matching given requirement. If LLM can provide a remarkable effect for understanding given requirement and obeying the order there will be many groups and individuals of human developers who are benefited.
